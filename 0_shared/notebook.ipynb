{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def call_openai_llm(prompt, model=\"gpt-4\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Call OpenAI's language model with the given prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt to send to the model\n",
    "        model (str): The OpenAI model to use (default: gpt-4)\n",
    "        temperature (float): Controls randomness in the output (0.0-1.0)\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load API key from .env file\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Initialize the client\n",
    "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling OpenAI API: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_openai_llm(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing note: raw_notes/coffee thought.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/ideas/Coffee Consumption in Lifestyle Surveys.md\n",
      "Processing note: raw_notes/intro paragraph idea.md\n",
      "Note organized to: organised_notes/thesis/chapter_1_tag/ideas/Introduction Idea - WHO Smoking Statistics.md\n",
      "Processing note: raw_notes/lit review note smith2023.md\n",
      "Note organized to: organised_notes/thesis/chapter_2/research_papers/Review_of_Smiths_Nicotine_Dependence_Measurement_Method.md\n",
      "Processing note: raw_notes/epi conf thing sept.md\n",
      "Note organized to: organised_notes/general/conferences/Notes from London Epidemiology Conference.md\n",
      "Processing note: raw_notes/amsterdam workshop notes.md\n",
      "Note organized to: organised_notes/general/conferences/Causal Inference Workshop Notes.md\n",
      "Processing note: raw_notes/!!!.md\n",
      "Note organized to: organised_notes/general/research_papers/Found_Paper_Reference.md\n",
      "Processing note: raw_notes/citation format.md\n",
      "Note organized to: organised_notes/todo/Update Zotero to APA 7th Edition.md\n",
      "Processing note: raw_notes/CONSPIRACY THEORY!!!.md\n",
      "Note organized to: organised_notes/general/ideas/Satirical Conspiracy Theories.md\n",
      "Processing note: raw_notes/2nd tue thing.md\n",
      "Note organized to: organised_notes/thesis/chapter_2/ideas/Meeting Feedback and Next Steps.md\n",
      "Processing note: raw_notes/browser tabs from yesterday.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/research_papers/Methodology_and_Research_Papers_for_Lifestyle_Study.md\n",
      "Processing note: raw_notes/dream about statistics.md\n",
      "Note organized to: organised_notes/general/ideas/Stats Nightmare - A Fever Dream.md\n",
      "Processing note: raw_notes/look into this later maybe.md\n",
      "Note organized to: organised_notes/thesis/general/ideas/Exercise and Dopamine Idea from YouTube.md\n",
      "Processing note: raw_notes/methods symposium notes.md\n",
      "Note organized to: organised_notes/general/ideas/Conference Notes and Research Jokes.md\n",
      "Processing note: raw_notes/conference deadline.md\n",
      "Note organized to: organised_notes/todo/SRNT Abstract Submission Deadline.md\n",
      "Processing note: raw_notes/boston conf thing.md\n",
      "Note organized to: organised_notes/general/conferences/Epi Conference Notes.md\n",
      "Processing note: raw_notes/3am thoughts about pasta.md\n",
      "Note organized to: organised_notes/todo/Random Thoughts and Questions.md\n",
      "Processing note: raw_notes/missing data pattern.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/datasets/Missing Data in Evening Check-ins.md\n",
      "Processing note: raw_notes/check laterrrrr.md\n",
      "Note organized to: organised_notes/general/ideas/Reddit Thread Analysis on Quitting.md\n",
      "Processing note: raw_notes/meeting thought jan15.md\n",
      "Note organized to: organised_notes/todo/Geographic Clustering of Quit Attempts.md\n",
      "Processing note: raw_notes/figure idea.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/ideas/Sankey Diagram for Lifestyle Intervention Stages.md\n",
      "Processing note: raw_notes/misc resources.md\n",
      "Note organized to: organised_notes/general/tools/Useful Writing and Productivity Tools.md\n",
      "Processing note: raw_notes/income correlation idea.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/ideas/Hypothesis on Income and Smoking Relationship.md\n",
      "Processing note: raw_notes/battery life.md\n",
      "Note organized to: organised_notes/todo/App Battery Drain Issue.md\n",
      "Processing note: raw_notes/dream idea.md\n",
      "Note organized to: organised_notes/todo/Dreamt_Interaction_Effects.md\n",
      "Processing note: raw_notes/lab meeting memes.md\n",
      "Note organized to: organised_notes/general/ideas/Humorous Lab Presentation Ideas.md\n",
      "Processing note: raw_notes/funding idea.md\n",
      "Note organized to: organised_notes/todo/Cancer Research Foundation Grants for Smoking Cessation Studies.md\n",
      "Processing note: raw_notes/cat diary entry 47.md\n",
      "Note organized to: organised_notes/general/ideas/Observations and Chaos Theory A Cats Perspective.md\n",
      "Processing note: raw_notes/late night idea.md\n",
      "Note organized to: organised_notes/general/ideas/Social Media Sentiment Analysis During Quit Attempts.md\n",
      "Processing note: raw_notes/lit gap.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/ideas/Potential Research on Vaping as a Gateway Back to Smoking.md\n",
      "Processing note: raw_notes/aaaaa.md\n",
      "Note organized to: organised_notes/thesis/chapter_1/ideas/Moon Phases and Lifestyle Quit Rates.md\n",
      "Processing note: raw_notes/asdfghjkl.md\n",
      "Note organized to: organised_notes/general/ideas/Thoughts on Longitudinal Data Analysis.md\n",
      "Processing note: raw_notes/ethics concern.md\n",
      "Note organized to: organised_notes/todo/Ethics Application Clarification Regarding Pregnant Participants.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration --- #\n",
    "class Config:\n",
    "    RAW_NOTES_DIR = \"raw_notes\"\n",
    "    ORGANIZED_NOTES_DIR = \"organised_notes\"\n",
    "    MAPPING_CSV = \"note_mapping.csv\"\n",
    "    \n",
    "    CHAPTER_TAGS = {\n",
    "        \"chapter_1\": \"#lifestyle\",\n",
    "        \"chapter_2\": \"#heart\"\n",
    "    }\n",
    "    \n",
    "    SECTION_TAGS = {\"chapter_1_section_1\": CHAPTER_TAGS['chapter_1'] + \"-introduction\",\n",
    "                    \"chapter_1_section_2\": CHAPTER_TAGS['chapter_1'] + \"-analysis\",\n",
    "                    \"chapter_1_section_3\": CHAPTER_TAGS['chapter_1'] + \"-conclusion\",\n",
    "                    \"chapter_2_section_1\": CHAPTER_TAGS['chapter_2'] + \"-introduction\",\n",
    "                    \"chapter_2_section_2\": CHAPTER_TAGS['chapter_2'] + \"-analysis\",\n",
    "                    \"chapter_2_section_3\": CHAPTER_TAGS['chapter_2'] + \"-conclusion\"}\n",
    "    \n",
    "    ADDITIONAL_TAGS = [\n",
    "        \"#todo\", \"#thesis\", \"#research\", \"#datasets\", \n",
    "        \"#ideas\", \"#tools\", \"#conferences\"\n",
    "    ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_prompt_template(note_content):\n",
    "        return f\"\"\"\n",
    "You are a categorization assistant specialized in organizing research and PhD thesis notes.\n",
    "You have a predefined folder hierarchy:\n",
    "- todo\n",
    "- thesis: which contains chapters (e.g., chapter_1_tag, chapter_2_tag, etc.). Inside each chapter the note can be further organized into:\n",
    "    - datasets\n",
    "    - research_papers\n",
    "    - ideas\n",
    "- general: which contains:\n",
    "    - datasets\n",
    "    - research_papers\n",
    "    - ideas\n",
    "    - tools\n",
    "    - conferences\n",
    "\n",
    "The thesis has the following chapter tags:\n",
    "{json.dumps(Config.CHAPTER_TAGS, indent=2)}\n",
    "\n",
    "And section tags:\n",
    "{json.dumps(Config.SECTION_TAGS, indent=2)}\n",
    "\n",
    "The additional tags for notes are:\n",
    "{json.dumps(Config.ADDITIONAL_TAGS, indent=2)}\n",
    "\n",
    "Analyze the following note's content. The note may contain some tags (e.g., #todo or #research) that provide hints about its content.\n",
    "\n",
    "From the note, please decide:\n",
    "1. The overall category for the note (it can be \"todo\", \"thesis\", or \"general\").\n",
    "2. If it belongs under \"thesis\", assign a chapter such as \"{Config.CHAPTER_TAGS['chapter_1']}\" or \"{Config.CHAPTER_TAGS['chapter_2']}\" and, if applicable, a further subcategory (one of: \"datasets\", \"research papers\", \"ideas\").\n",
    "3. If it belongs under \"general\", choose one subcategory from (\"datasets\", \"research papers\", \"ideas\", \"tools\", \"conferences\").\n",
    "4. Optionally, update the tags using only those from the allowed set.\n",
    "5. Suggest an appropriate title for the note.\n",
    "\n",
    "Please output a JSON string with exactly these keys:\n",
    "- \"folder_structure\": a string defining the folder path relative to the organized notes directory (for example, \"thesis/chapter_1/ideas\", \"todo\", or \"general/tools\").\n",
    "- \"file_title\": a string representing the new title for the note (do not include a file extension).\n",
    "- \"tags\": a list of strings where each string is a tag (starting with '#') from the allowed set that apply to this note.\n",
    "\n",
    "Here is the note content:\n",
    "{note_content}\n",
    "\"\"\"\n",
    "\n",
    "class FileUtils:\n",
    "    @staticmethod\n",
    "    def compute_file_hash(file_path):\n",
    "        \"\"\"Compute MD5 hash of the file content to detect changes.\"\"\"\n",
    "        hasher = hashlib.md5()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            buffer = f.read()\n",
    "            hasher.update(buffer)\n",
    "        return hasher.hexdigest()\n",
    "    \n",
    "    @staticmethod\n",
    "    def sanitize_filename(filename):\n",
    "        \"\"\"Ensure filename is safe (alphanumeric and selected characters)\"\"\"\n",
    "        return \"\".join(c for c in filename if c.isalnum() or c in (' ', '_', '-')).rstrip()\n",
    "\n",
    "class LLMHandler:\n",
    "    @staticmethod\n",
    "    def get_llm_response(note_content):\n",
    "        \"\"\"Get categorization from OpenAI's GPT API\"\"\"\n",
    "        prompt = Config.get_prompt_template(note_content)\n",
    "        try:\n",
    "            response = call_openai_llm(prompt, temperature=0.5)\n",
    "            if response:\n",
    "                try:\n",
    "                    return json.loads(response)\n",
    "                except json.JSONDecodeError:\n",
    "                    import re\n",
    "                    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "                    if json_match:\n",
    "                        return json.loads(json_match.group())\n",
    "                    raise ValueError(\"Unable to extract JSON from LLM response.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LLM API call: {e}\")\n",
    "            return None\n",
    "\n",
    "class NoteWriter:\n",
    "    @staticmethod\n",
    "    def write_organized_note(note_content, llm_result, raw_file_path):\n",
    "        \"\"\"Write note to organized folder structure\"\"\"\n",
    "        folder_structure = llm_result.get(\"folder_structure\", \"general\")\n",
    "        file_title = FileUtils.sanitize_filename(llm_result.get(\"file_title\", \"untitled\"))\n",
    "        \n",
    "        dest_dir = os.path.join(Config.ORGANIZED_NOTES_DIR, folder_structure)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        dest_file_path = os.path.join(dest_dir, f\"{file_title}.md\")\n",
    "        \n",
    "        raw_note_link = f\"[[{os.path.relpath(raw_file_path, start=Config.ORGANIZED_NOTES_DIR)}]]\"\n",
    "        new_tags = llm_result.get(\"tags\", [])\n",
    "        tags_str = \"\\n\".join(new_tags) if new_tags else \"\"\n",
    "        \n",
    "        organized_content = f\"{tags_str}\\n\\n{raw_note_link}\\n\\n{note_content}\"\n",
    "        \n",
    "        with open(dest_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(organized_content)\n",
    "        \n",
    "        return dest_file_path\n",
    "\n",
    "class MappingManager:\n",
    "    @staticmethod\n",
    "    def load_mapping():\n",
    "        \"\"\"Load CSV mapping file\"\"\"\n",
    "        if os.path.exists(Config.MAPPING_CSV):\n",
    "            return pd.read_csv(Config.MAPPING_CSV)\n",
    "        return pd.DataFrame(columns=[\"raw_note_path\", \"organized_note_path\", \"file_hash\", \"processed_time\", \"llm_response\"])\n",
    "    \n",
    "    @staticmethod\n",
    "    def update_mapping(mapping_df):\n",
    "        \"\"\"Save mapping DataFrame to CSV\"\"\"\n",
    "        mapping_df.to_csv(Config.MAPPING_CSV, index=False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_mapping_entry(raw_file_path, organized_note_path, file_hash, llm_result):\n",
    "        \"\"\"Create new mapping DataFrame entry\"\"\"\n",
    "        return pd.DataFrame([{\n",
    "            \"raw_note_path\": raw_file_path,\n",
    "            \"organized_note_path\": organized_note_path,\n",
    "            \"file_hash\": file_hash,\n",
    "            \"processed_time\": datetime.now().isoformat(),\n",
    "            \"llm_response\": json.dumps(llm_result)\n",
    "        }])\n",
    "\n",
    "class NoteProcessor:\n",
    "    def __init__(self):\n",
    "        self.mapping_df = MappingManager.load_mapping()\n",
    "        self.processed_notes = dict(zip(self.mapping_df[\"raw_note_path\"], self.mapping_df[\"file_hash\"]))\n",
    "    \n",
    "    def process_single_note(self, raw_file_path):\n",
    "        \"\"\"Process a single note file\"\"\"\n",
    "        file_hash = FileUtils.compute_file_hash(raw_file_path)\n",
    "        \n",
    "        if raw_file_path in self.processed_notes and self.processed_notes[raw_file_path] == file_hash:\n",
    "            print(f\"Skipping unchanged note: {raw_file_path}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Processing note: {raw_file_path}\")\n",
    "        try:\n",
    "            with open(raw_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                note_content = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {raw_file_path}: {e}\")\n",
    "            return\n",
    "            \n",
    "        llm_result = LLMHandler.get_llm_response(note_content)\n",
    "        if llm_result is None:\n",
    "            print(f\"LLM did not return a valid response for note: {raw_file_path}\")\n",
    "            return\n",
    "            \n",
    "        organized_note_path = NoteWriter.write_organized_note(note_content, llm_result, raw_file_path)\n",
    "        print(f\"Note organized to: {organized_note_path}\")\n",
    "        \n",
    "        new_row = MappingManager.create_mapping_entry(raw_file_path, organized_note_path, file_hash, llm_result)\n",
    "        \n",
    "        if raw_file_path in self.processed_notes:\n",
    "            self.mapping_df.loc[self.mapping_df[\"raw_note_path\"] == raw_file_path, :] = new_row.iloc[0]\n",
    "        else:\n",
    "            self.mapping_df = pd.concat([self.mapping_df, new_row], ignore_index=True)\n",
    "        \n",
    "        MappingManager.update_mapping(self.mapping_df)\n",
    "    \n",
    "    def process_all_notes(self):\n",
    "        \"\"\"Process all notes in the raw notes directory\"\"\"\n",
    "        for root, _, files in os.walk(Config.RAW_NOTES_DIR):\n",
    "            for file in files:\n",
    "                if file.endswith(\".md\"):\n",
    "                    raw_file_path = os.path.join(root, file)\n",
    "                    self.process_single_note(raw_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = NoteProcessor()\n",
    "    processor.process_all_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
